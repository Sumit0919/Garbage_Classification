{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvOGtW6IPDHuoGAyUbAERk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sumit0919/Garbage_Classification/blob/main/Copy_of_Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzZgn_6OLi0i",
        "outputId": "a5f9bdb9-e8b4-4ca7-d700-015e30f4aa97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crop Recommendation Model trained and saved successfully!\n",
            "Model Accuracy: 0.9931818181818182\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import the necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pickle\n",
        "\n",
        "# Step 2: Load your dataset from the uploaded file\n",
        "df = pd.read_csv('Crop_recommendation.csv')\n",
        "\n",
        "# Step 3: Define your features (X) and the target (y)\n",
        "# X contains all the input columns (N, P, K, temp, etc.)\n",
        "# y contains the output column ('label', which is the crop name)\n",
        "X = df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
        "y = df['label']\n",
        "\n",
        "# Step 4: Split the data for training and testing the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Create and train the Random Forest model\n",
        "# This model is great at learning patterns from this kind of data.\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Save your trained model to a file\n",
        "# We save it so we can use it later in our web app without retraining.\n",
        "with open('crop_recommendation_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n",
        "\n",
        "# Step 7: Print a success message and check the model's accuracy\n",
        "print(\"Crop Recommendation Model trained and saved successfully!\")\n",
        "print(\"Model Accuracy:\", model.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import the necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# Step 2: Load the dataset\n",
        "df_yield = pd.read_csv('crop_production.csv')\n",
        "\n",
        "# Step 3: Pre-process the data\n",
        "# We remove rows where the 'Production' value is missing, as we can't learn from them.\n",
        "df_yield.dropna(subset=['Production'], inplace=True)\n",
        "\n",
        "# Create our target variable 'Yield' (Production per Area)\n",
        "df_yield['Yield'] = df_yield['Production'] / df_yield['Area']\n",
        "\n",
        "# Convert text columns into numbers so the model can understand them\n",
        "# We will use the most important columns for prediction\n",
        "le_state = LabelEncoder()\n",
        "le_crop = LabelEncoder()\n",
        "\n",
        "df_yield['State_Encoded'] = le_state.fit_transform(df_yield['State_Name'])\n",
        "df_yield['Crop_Encoded'] = le_crop.fit_transform(df_yield['Crop'])\n",
        "\n",
        "# Step 4: Define features (X) and target (y)\n",
        "X_yield = df_yield[['State_Encoded', 'Crop_Encoded', 'Crop_Year', 'Area']]\n",
        "y_yield = df_yield['Yield']\n",
        "\n",
        "# Step 5: Split data and train the model\n",
        "X_train_y, X_test_y, y_train_y, y_test_y = train_test_split(X_yield, y_yield, test_size=0.2, random_state=42)\n",
        "\n",
        "# We use RandomForestRegressor because we are predicting a number (the yield)\n",
        "yield_model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1) # n_jobs=-1 uses all your computer's power to run faster\n",
        "yield_model.fit(X_train_y, y_train_y)\n",
        "\n",
        "# Step 6: Save the trained model\n",
        "with open('yield_prediction_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(yield_model, model_file)\n",
        "\n",
        "# Step 7: Print success message and check the model's score\n",
        "# The score (R-squared) tells us how well the model's predictions match the real data.\n",
        "print(\"Yield Prediction Model trained and saved successfully!\")\n",
        "print(\"Model Score:\", yield_model.score(X_test_y, y_test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6crefABNYJ4",
        "outputId": "70c862ce-a997-475a-80a0-88d3f4fd9977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yield Prediction Model trained and saved successfully!\n",
            "Model Score: 0.7112704207712509\n"
          ]
        }
      ]
    }
  ]
}